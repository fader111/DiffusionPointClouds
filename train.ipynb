{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.4.0+cu124', 'cuda available')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from points_dataset import EmbedderDataset\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "from models import *\n",
    "from point_cloud_dataset import PointCloudDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.__version__, \"cuda available\" if torch.cuda.is_available() else \"cpu only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5010858\\AppData\\Local\\Temp/ipykernel_16964/2826452364.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  point_cloud_ds = torch.load(point_cloud_ds_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device, ds length - 27341, data.shape - (27341, 3072)\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "\n",
    "# ds_path = r\"C:\\Projects\\multiSetup\\datasets_embedded\\ds_1024.pth\"\n",
    "# point_cloud_ds_path = r\"C:\\Projects\\multiSetup\\datasets_embedded\\ds_256.pth\"\n",
    "point_cloud_ds_path = r\"dataset_points\\ds_1024_head.pth\"\n",
    "point_cloud_ds = torch.load(point_cloud_ds_path)\n",
    "point_cloud_dataset_data = point_cloud_ds.data\n",
    "\n",
    "print(f\"Using {device} device, ds length - {len(point_cloud_ds)}, data.shape - {point_cloud_dataset_data.shape}\")\n",
    "\n",
    "EPOCHS = 560\n",
    "BATCH_SIZE = 128\n",
    "SPLIT_FACTOR = .8\n",
    "TRAIN_MODE = (False, True)[1]\n",
    "REMOVE_OLD_MODELS = True\n",
    "POINTS_PER_SHAPE = 1024\n",
    "POINT_DIM = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "diffision_ae_ds = PointCloudDataset(torch.from_numpy(point_cloud_dataset_data), k=6)\n",
    "len(diffision_ae_ds)\n",
    "train_loader = DataLoader(diffision_ae_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_loader))\n",
    "# batch # DataBatch(x=[131072, 3], edge_index=[2, 786432], edge_weight=[786432], batch=[131072], ptr=[129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/560, Loss: 504.8459463386892\n",
      "Best model saved with loss 504.8459463386892 at epoch 0\n",
      "Epoch 1/560, Loss: 38.80685969379461\n",
      "Best model saved with loss 38.80685969379461 at epoch 1\n",
      "Epoch 2/560, Loss: 23.692380664504576\n",
      "Best model saved with loss 23.692380664504576 at epoch 2\n",
      "Epoch 3/560, Loss: 17.21518500497408\n",
      "Best model saved with loss 17.21518500497408 at epoch 3\n",
      "Epoch 4/560, Loss: 13.804099216639438\n",
      "Best model saved with loss 13.804099216639438 at epoch 4\n",
      "Epoch 5/560, Loss: 11.518624417135648\n",
      "Best model saved with loss 11.518624417135648 at epoch 5\n",
      "Epoch 6/560, Loss: 9.96742689275296\n",
      "Best model saved with loss 9.96742689275296 at epoch 6\n",
      "Epoch 7/560, Loss: 8.83157965847265\n",
      "Best model saved with loss 8.83157965847265 at epoch 7\n",
      "Epoch 8/560, Loss: 7.93142168098521\n",
      "Best model saved with loss 7.93142168098521 at epoch 8\n",
      "Epoch 9/560, Loss: 7.06536657565108\n",
      "Best model saved with loss 7.06536657565108 at epoch 9\n",
      "Epoch 10/560, Loss: 6.318931742249248\n",
      "Best model saved with loss 6.318931742249248 at epoch 10\n",
      "Epoch 11/560, Loss: 5.764494967237812\n",
      "Best model saved with loss 5.764494967237812 at epoch 11\n",
      "Epoch 12/560, Loss: 5.333540366074749\n",
      "Best model saved with loss 5.333540366074749 at epoch 12\n",
      "Epoch 13/560, Loss: 6.81755241278176\n",
      "Epoch 14/560, Loss: 4.366100108512094\n",
      "Best model saved with loss 4.366100108512094 at epoch 14\n",
      "Epoch 15/560, Loss: 3.8962144183221263\n",
      "Best model saved with loss 3.8962144183221263 at epoch 15\n",
      "Epoch 16/560, Loss: 4.021035962015669\n",
      "Epoch 17/560, Loss: 3.367405698678204\n",
      "Best model saved with loss 3.367405698678204 at epoch 17\n",
      "Epoch 18/560, Loss: 3.3265566424788715\n",
      "Best model saved with loss 3.3265566424788715 at epoch 18\n",
      "Epoch 19/560, Loss: 4.611869994725023\n",
      "Epoch 20/560, Loss: 3.0573598012745937\n",
      "Best model saved with loss 3.0573598012745937 at epoch 20\n",
      "Epoch 21/560, Loss: 2.4662692903358248\n",
      "Best model saved with loss 2.4662692903358248 at epoch 21\n",
      "Epoch 22/560, Loss: 2.3310171298891587\n",
      "Best model saved with loss 2.3310171298891587 at epoch 22\n",
      "Epoch 23/560, Loss: 2.5987849792587423\n",
      "Epoch 24/560, Loss: 2.1383905126669696\n",
      "Best model saved with loss 2.1383905126669696 at epoch 24\n",
      "Epoch 25/560, Loss: 2.1039359196324217\n",
      "Best model saved with loss 2.1039359196324217 at epoch 25\n",
      "Epoch 26/560, Loss: 2.143624023299351\n",
      "Epoch 27/560, Loss: 1.7320972424801264\n",
      "Best model saved with loss 1.7320972424801264 at epoch 27\n",
      "Epoch 28/560, Loss: 1.835127689571024\n",
      "Epoch 29/560, Loss: 1.6836998546234916\n",
      "Best model saved with loss 1.6836998546234916 at epoch 29\n",
      "Epoch 30/560, Loss: 1.6599097212898397\n",
      "Best model saved with loss 1.6599097212898397 at epoch 30\n",
      "Epoch 31/560, Loss: 1.382884067352687\n",
      "Best model saved with loss 1.382884067352687 at epoch 31\n",
      "Epoch 32/560, Loss: 1.4556450531861493\n",
      "Epoch 33/560, Loss: 1.273324708236712\n",
      "Best model saved with loss 1.273324708236712 at epoch 33\n",
      "Epoch 34/560, Loss: 1.3238780771460488\n",
      "Epoch 35/560, Loss: 1.2212618352653823\n",
      "Best model saved with loss 1.2212618352653823 at epoch 35\n",
      "Epoch 36/560, Loss: 1.1398083119191855\n",
      "Best model saved with loss 1.1398083119191855 at epoch 36\n",
      "Epoch 37/560, Loss: 1.034287599481155\n",
      "Best model saved with loss 1.034287599481155 at epoch 37\n",
      "Epoch 38/560, Loss: 0.9797304250369562\n",
      "Best model saved with loss 0.9797304250369562 at epoch 38\n",
      "Epoch 39/560, Loss: 0.9007505482045289\n",
      "Best model saved with loss 0.9007505482045289 at epoch 39\n",
      "Epoch 40/560, Loss: 0.8855229780495724\n",
      "Best model saved with loss 0.8855229780495724 at epoch 40\n",
      "Epoch 41/560, Loss: 0.8550068616310013\n",
      "Best model saved with loss 0.8550068616310013 at epoch 41\n",
      "Epoch 42/560, Loss: 0.92169158313876\n",
      "Epoch 43/560, Loss: 0.7122574225764409\n",
      "Best model saved with loss 0.7122574225764409 at epoch 43\n",
      "Epoch 44/560, Loss: 0.7481821067979403\n",
      "Epoch 45/560, Loss: 2.7854089645024773\n",
      "Epoch 46/560, Loss: 0.6790591968554203\n",
      "Best model saved with loss 0.6790591968554203 at epoch 46\n",
      "Epoch 47/560, Loss: 0.570399112512018\n",
      "Best model saved with loss 0.570399112512018 at epoch 47\n",
      "Epoch 48/560, Loss: 0.5884571728583808\n",
      "Epoch 49/560, Loss: 0.5124649949998499\n",
      "Best model saved with loss 0.5124649949998499 at epoch 49\n",
      "Epoch 50/560, Loss: 0.5101483866711644\n",
      "Best model saved with loss 0.5101483866711644 at epoch 50\n",
      "Epoch 51/560, Loss: 0.4937232695171766\n",
      "Best model saved with loss 0.4937232695171766 at epoch 51\n",
      "Epoch 52/560, Loss: 0.5845285129045772\n",
      "Epoch 53/560, Loss: 0.45366349133932704\n",
      "Best model saved with loss 0.45366349133932704 at epoch 53\n",
      "Epoch 54/560, Loss: 0.4649840675503294\n",
      "Epoch 55/560, Loss: 0.5048176062719845\n",
      "Epoch 56/560, Loss: 0.3454298443187063\n",
      "Best model saved with loss 0.3454298443187063 at epoch 56\n",
      "Epoch 57/560, Loss: 0.4393613788986874\n",
      "Epoch 58/560, Loss: 0.36353740945597673\n",
      "Epoch 59/560, Loss: 0.35350078685539904\n",
      "Epoch 60/560, Loss: 0.4219952912948956\n",
      "Epoch 61/560, Loss: 0.32586250677008494\n",
      "Best model saved with loss 0.32586250677008494 at epoch 61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m model \u001b[38;5;241m=\u001b[39m DiffusionNetAutoencoder(POINT_DIM, hidden_features, latent_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Call the training function with TensorBoard logging\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[1;34m(model, train_loader, device, epochs, lr, log_dir)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     12\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     14\u001b[0m         x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mx  \u001b[38;5;66;03m# Node features for all graphs in the batch\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         edge_index \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39medge_index  \u001b[38;5;66;03m# Edge indices for all graphs in the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Projects\\DiffusionPointClouds\\point_cloud_dataset.py:27\u001b[0m, in \u001b[0;36mPointCloudDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     24\u001b[0m point_cloud \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_clouds[idx]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# shape {num_points, point_dim}\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create edge_index using k-nearest neighbors (kNN)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mknn_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: [2, num_edges]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute Laplacian (sparse form using edge weights)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_edge_weight(edge_index, point_cloud\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch_geometric\\nn\\pool\\__init__.py:130\u001b[0m, in \u001b[0;36mknn_graph\u001b[1;34m(x, k, batch, loop, flow, cosine, num_workers)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mknn_graph\u001b[39m(x: Tensor, k: \u001b[38;5;28mint\u001b[39m, batch: OptTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, loop: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m               flow: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m, cosine: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m               num_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes graph edges to the nearest :obj:`k` points.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m        edge_index = knn_graph(x, k=2, batch=batch, loop=False)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch_cluster\\knn.py:132\u001b[0m, in \u001b[0;36mknn_graph\u001b[1;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes graph edges to the nearest :obj:`k` points.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    edge_index = knn_graph(x, k=2, batch=batch, loop=False)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_to_source\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 132\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    136\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m], edge_index[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch_cluster\\knn.py:81\u001b[0m, in \u001b[0;36mknn\u001b[1;34m(x, y, k, batch_x, batch_y, cosine, num_workers, batch_size)\u001b[0m\n\u001b[0;32m     78\u001b[0m     ptr_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbucketize(arange, batch_x)\n\u001b[0;32m     79\u001b[0m     ptr_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbucketize(arange, batch_y)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\torch\\_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[1;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_autoencoder(model, train_loader, device, epochs=EPOCHS, lr=1e-3, log_dir=\"runs/autoencoder\"):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    best_loss = float('inf')  # Initialize best loss to infinity\n",
    "    best_model_path = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            x = batch.x  # Node features for all graphs in the batch\n",
    "            edge_index = batch.edge_index  # Edge indices for all graphs in the batch\n",
    "            edge_weight = batch.edge_weight  # Edge weights (Laplacian) for all graphs in the batch\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to the specified device (GPU or CPU)\n",
    "            x = x.to(device)  # torch.Size([128, 1024, 3])\n",
    "            edge_index = edge_index.to(device)  # torch.Size([128, 2, 6144])\n",
    "            edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            reconstructed, _ = model(x, edge_index, edge_weight=edge_weight)\n",
    "            loss = loss_fn(reconstructed, x)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss for the epoch\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Log batch-level loss to TensorBoard\n",
    "            writer.add_scalar('Loss/train_batch', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "        # Average loss per epoch\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        # Log epoch-level loss to TensorBoard\n",
    "        writer.add_scalar('Loss/train_epoch', avg_epoch_loss, epoch)\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Epoch {epoch}/{epochs}, Loss: {avg_epoch_loss}')\n",
    "\n",
    "        # Check if the current model is the best one (based on loss)\n",
    "        if avg_epoch_loss < best_loss:\n",
    "            best_loss = avg_epoch_loss\n",
    "            best_model_path = f\"models/best_model_epoch_{epoch}.pth\"\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            torch.save(model.encoder.state_dict(), f\"models/encoder_{epoch}.pth\")\n",
    "            torch.save(model.decoder.state_dict(), f\"models/decoder_{epoch}.pth\")\n",
    "\n",
    "            print(f\"Best model saved with loss {best_loss} at epoch {epoch}\")\n",
    "\n",
    "    # Close TensorBoard writer when training is complete\n",
    "    writer.close()\n",
    "\n",
    "    # Return the path to the best model for further usage\n",
    "    return best_model_path\n",
    "\n",
    "# Initialize and train the model\n",
    "hidden_features = 64\n",
    "latent_dim = 32\n",
    "\n",
    "model = DiffusionNetAutoencoder(POINT_DIM, hidden_features, latent_dim).to(device)\n",
    "\n",
    "# Call the training function with TensorBoard logging\n",
    "best_model_path = train_autoencoder(model, train_loader, device)\n",
    "print(f\"Best model saved at: {best_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
